{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from othello_rules import *\n",
    "from othello_net import *\n",
    "from tensorflow.python.framework import ops\n",
    "from datetime import datetime\n",
    "from example_states import *\n",
    "from feature_extractor import *\n",
    "from training_utils import *\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def value_error(data_path, sess, diagnostics=False):\n",
    "    errors = []\n",
    "    validation_matches = get_all_matches(data_path)\n",
    "    #XXX: Delete this line when testing is faster\n",
    "    validation_matches = validation_matches[0:30]\n",
    "    for i in range(len(validation_matches)):\n",
    "        if diagnostics:\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>new game\")\n",
    "        match = validation_matches[i]\n",
    "        raw_match_movelist = match[8:]\n",
    "        unpacked_movelist = unpack('b'*60, raw_match_movelist)\n",
    "        black_score = match[6]\n",
    "        unpacked_black_score = unpack('b', black_score)\n",
    "        winner = -1 if unpacked_black_score[0] > 32 else 1\n",
    "        board = initialize_game()\n",
    "        player = -1\n",
    "        \n",
    "        if diagnostics:\n",
    "            print(unpacked_black_score)\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>winner is \" + str(winner))\n",
    "        movenr = 0\n",
    "        for move in unpacked_movelist:\n",
    "            if move == 0:\n",
    "                break\n",
    "            feature_path = 'cache/validation/features/features_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            label_path = 'cache/validation/labels/labels_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            if os.path.isfile(feature_path) and os.path.isfile(label_path):\n",
    "                features = np.load(feature_path)\n",
    "            else:\n",
    "                features = board_to_input(board, player)\n",
    "                \n",
    "            input_batch = [features]\n",
    "            #s = 1 if player * (-1) == winner else 0\n",
    "            if winner == -1:\n",
    "                r = ([0, 1])\n",
    "                #r = [[0]]\n",
    "            else:\n",
    "                r = ([1, 0])\n",
    "                #r = [[1]]\n",
    "            label_batch = [r]\n",
    "            \n",
    "\n",
    "            if diagnostics and movenr > 52:\n",
    "                estimate = sess.run(score_out, feed_dict={img_data:input_batch, keep_prob:1.0})\n",
    "                predictions = sess.run(score_out, feed_dict={img_data:input_batch, keep_prob:1.0})\n",
    "                predic = predictions[0][0][0]\n",
    "                prediction = list_softmax(predic)\n",
    "                print(\"-new state-\")\n",
    "                print(\"actual value: \" + str(r))\n",
    "                #print(\"score_out: \" + str(estimate))\n",
    "                print(\"predictions: \" + str(prediction))\n",
    "            movenr += 1\n",
    "            if np.count_nonzero(board) == 64:\n",
    "                print(\"ok got some\")\n",
    "                error = sess.run(loss, feed_dict={img_data:input_batch, ground_truths: label_batch, keep_prob:1.0})\n",
    "                errors.append(error)\n",
    "            board = make_move(board, move, player)\n",
    "            if player is 1:\n",
    "                player = -1\n",
    "            else:\n",
    "                player = 1\n",
    "            legal_moves = find_legal_moves(board, player)\n",
    "            if len(legal_moves) == 0:\n",
    "                if player is 1:\n",
    "                    player = -1\n",
    "                else:\n",
    "                    player = 1\n",
    "                    \n",
    "        if np.count_nonzero(board) == 64:\n",
    "            error = sess.run(loss, feed_dict={img_data:input_batch, ground_truths: label_batch, keep_prob:1.0})\n",
    "            errors.append(error)\n",
    "            predic = sess.run(score_out, feed_dict={img_data:input_batch, ground_truths: label_batch, keep_prob:1.0})\n",
    "            predic = predic[0][0][0]\n",
    "            prediction = list_softmax(predic)\n",
    "            if diagnostics:\n",
    "                print(\"target is \")\n",
    "                print(r)\n",
    "                print(\"prediction is:\")\n",
    "                print(prediction)\n",
    "    return np.sum(errors) / len(errors)\n",
    "\n",
    "def list_softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    sf = np.exp(x)\n",
    "    sf = sf/np.sum(sf, axis=0)\n",
    "    return sf\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def lrelu(x, leak=0.05, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)\n",
    "\n",
    "def conv_nonparams2(tensor_input, conv_weights, conv_biases, keep_prob):\n",
    "    conv_in = conv(tensor_input, conv_weights)\n",
    "    conv_relu = lrelu(conv_in + conv_biases)\n",
    "    conv_drop = tf.nn.dropout(conv_relu, keep_prob)\n",
    "    return conv_drop\n",
    "\n",
    "def conv_weights2(i, o):\n",
    "    k = 2\n",
    "    shape = [k, k, i, o]\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv_nonparams3(tensor_input, conv_weights, conv_biases, keep_prob):\n",
    "    conv_in = conv(tensor_input, conv_weights, \"VALID\")\n",
    "    conv_relu = lrelu(conv_in + conv_biases)\n",
    "    conv_drop = tf.nn.dropout(conv_relu, keep_prob)\n",
    "    return conv_drop\n",
    "\n",
    "def create_value_net():\n",
    "    with tf.name_scope(\"value_network\"):\n",
    "        img_data = tf.placeholder(tf.float32, shape=[None, 8, 8, 28], name=\"img_data\")\n",
    "        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "        #convolutional layers \n",
    "        i = 28; o = 32;\n",
    "        conv1_weights = conv_weights(i, o)\n",
    "        conv1_biases = conv_biases(o)\n",
    "        conv1_out = conv_nonparams2(img_data, conv1_weights, conv1_biases, keep_prob)\n",
    "        #pool1 = max_pool_2x2(conv1_out)\n",
    "        i = o; o = 32;\n",
    "        conv2_weights = conv_weights(i, o)\n",
    "        conv2_biases = conv_biases(o)\n",
    "        conv2_out = conv_nonparams2(conv1_out, conv2_weights, conv2_biases, keep_prob)\n",
    "        #pool2 = max_pool_2x2(conv2_out)\n",
    "        i = o; o = 32;\n",
    "        conv3_weights = conv_weights2(i, o)\n",
    "        conv3_biases = conv_biases(o)\n",
    "        conv3_out = conv_nonparams2(conv2_out, conv3_weights, conv3_biases, keep_prob)\n",
    "        \n",
    "        k = 1; i = o; o = 2;\n",
    "        s_weights = weight_variable([k, k, i, o])\n",
    "        s_biases = bias_variable([o])\n",
    "        s_out = conv_nonparams(conv3_out, s_weights, s_biases, keep_prob)\n",
    "        \n",
    "        k = 8; i = o; o = 2;\n",
    "        score_weights = weight_variable([k, k, i, o])\n",
    "        score_biases = bias_variable([o])\n",
    "        score_out = conv_nonparams3(s_out, score_weights, score_biases, keep_prob)\n",
    "        score_out_flat = tf.reshape(score_out, [-1, o])\n",
    "        #final layer\n",
    "        #Don't actually use this layer here\n",
    "        predictions = softmax(score_out, o)\n",
    "\n",
    "        #training block:\n",
    "        label = tf.placeholder(tf.float32, shape=[None, 2], name=\"ground_truths\")\n",
    "        learn_rate = tf.placeholder(tf.float32, name=\"eta\")\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(score_out_flat, label))\n",
    "        policy_network_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        reg_loss = tf.reduce_sum([tf.reduce_sum(tf.square(x)) for x in policy_network_variables])\n",
    "        optimizer = tf.train.AdamOptimizer(learn_rate)\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "        return sess.graph, img_data, train_step, optimizer, label, loss, predictions, keep_prob, learn_rate, score_out\n",
    "\n",
    "    # MAKE SURE that the topology of this network is the same as the policy network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117298\n",
      "start training\n",
      "14. Oct 21:53:25, Step 10000, Loss = 0.356059\n",
      "14. Oct 21:53:28, Step 10050, Loss = 0.355247\n",
      "14. Oct 21:53:31, Step 10100, Loss = 0.352786\n",
      "14. Oct 21:53:34, Step 10150, Loss = 0.345606\n",
      "14. Oct 21:53:37, Step 10200, Loss = 0.331047\n",
      "14. Oct 21:53:40, Step 10250, Loss = 0.318511\n",
      "14. Oct 21:53:43, Step 10300, Loss = 0.307684\n",
      "14. Oct 21:53:46, Step 10350, Loss = 0.303621\n",
      "14. Oct 21:53:50, Step 10400, Loss = 0.290966\n",
      "14. Oct 21:53:53, Step 10450, Loss = 0.280219\n",
      "14. Oct 21:53:56, Step 10500, Loss = 0.264914\n",
      "14. Oct 21:54:00, Step 10550, Loss = 0.258285\n",
      "14. Oct 21:54:03, Step 10600, Loss = 0.258079\n",
      "14. Oct 21:54:06, Step 10650, Loss = 0.258246\n",
      "14. Oct 21:54:09, Step 10700, Loss = 0.255146\n",
      "14. Oct 21:54:13, Step 10750, Loss = 0.255174\n",
      "14. Oct 21:54:16, Step 10800, Loss = 0.255818\n",
      "14. Oct 21:54:19, Step 10850, Loss = 0.258257\n",
      "14. Oct 21:54:22, Step 10900, Loss = 0.260643\n",
      "14. Oct 21:54:26, Step 10950, Loss = 0.273356\n",
      "14. Oct 21:54:29, Step 11000, Loss = 0.288609\n",
      "14. Oct 21:54:32, Step 11050, Loss = 0.289236\n",
      "14. Oct 21:54:36, Step 11100, Loss = 0.288531\n",
      "14. Oct 21:54:39, Step 11150, Loss = 0.307676\n",
      "14. Oct 21:54:42, Step 11200, Loss = 0.315027\n",
      "14. Oct 21:54:46, Step 11250, Loss = 0.312322\n",
      "14. Oct 21:54:49, Step 11300, Loss = 0.289159\n",
      "14. Oct 21:54:52, Step 11350, Loss = 0.273075\n",
      "14. Oct 21:54:56, Step 11400, Loss = 0.257431\n",
      "14. Oct 21:54:59, Step 11450, Loss = 0.253699\n",
      "14. Oct 21:55:02, Step 11500, Loss = 0.253409\n",
      "14. Oct 21:55:05, Step 11550, Loss = 0.257127\n",
      "14. Oct 21:55:09, Step 11600, Loss = 0.260306\n",
      "14. Oct 21:55:12, Step 11650, Loss = 0.262881\n",
      "14. Oct 21:55:15, Step 11700, Loss = 0.266979\n",
      "14. Oct 21:55:19, Step 11750, Loss = 0.265999\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "graph, img_data, train_step, optimizer, ground_truths, loss, pred_up, keep_prob, learn_rate, score_out = create_value_net()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess.run(init_op)\n",
    "#nopool7 gat fundið hver sigrar leiki, 0.2~ loss\n",
    "\n",
    "# Prófa noends9 upp á sanity checks\n",
    "current_model = \"models/sl-v/noends9.ckpt\"\n",
    "if os.path.isfile(current_model):\n",
    "    saver.restore(sess, current_model)\n",
    "validation_path = \"validation/\"\n",
    "matches = get_all_matches('training/')\n",
    "print(len(matches))\n",
    "\n",
    "# Byrjum þjálfunina\n",
    "print(\"start training\")\n",
    "#print(\"starting error:\" + str(avg_error(validation_path, sess)))\n",
    "#print('%s: Step %d: Prediction accuracy = %.2f' % (datetime.now(), 0,\n",
    "#                                                      prediction_accuracy()/float(60)))\n",
    "diagn = False\n",
    "if diagn:\n",
    "    iterations = 1\n",
    "else:\n",
    "    iterations = len(matches)\n",
    "prev_stop = 10000\n",
    "probs = 1\n",
    "eta = 2e-4\n",
    "input_batch = []\n",
    "label_batch = []\n",
    "for i in range(prev_stop, prev_stop+iterations):\n",
    "    #TODO: Skrifa þetta fall\n",
    "    #input_batch, label_batch = prepare_train_batch(train_ids, batch_size, do_flips, do_rots, data_path)\n",
    "    current_match = matches[i]\n",
    "    raw_match_movelist = current_match[8:]\n",
    "    unpacked_movelist = unpack('b'*60, raw_match_movelist)\n",
    "    black_score = current_match[6]\n",
    "    unpacked_black_score = unpack('b', black_score)\n",
    "    \n",
    "    #XXX: Temporary check for the value network, do this properly later\n",
    "    if unpacked_black_score[0] > 32:\n",
    "        winner = -1\n",
    "    else:\n",
    "        winner = 1\n",
    "    \n",
    "    board = initialize_game()\n",
    "    training_stability = np.zeros((8,8))\n",
    "    player = -1\n",
    "    \n",
    "    # One training batch is all the data from one match\n",
    "    if winner == -1:\n",
    "        r = ([0, 1])\n",
    "    else:\n",
    "        r = ([1, 0])\n",
    "    \n",
    "    for move in unpacked_movelist:\n",
    "        if move == 0:\n",
    "            break\n",
    "\n",
    "        if np.random.rand()>0.9:\n",
    "            feature_path = 'cache/training/features/features_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            label_path = 'cache/training/labels/labels_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            if os.path.isfile(feature_path) and os.path.isfile(label_path):\n",
    "                try:\n",
    "                    features = np.load(feature_path)\n",
    "                    label = np.load(label_path)\n",
    "                except:\n",
    "                    print(\"data corruption in match \" + str(i))\n",
    "                    features = board_to_input(board, player)\n",
    "                    label = prepare_data(move_to_label(move))\n",
    "            else:\n",
    "                features = board_to_input(board, player)\n",
    "                label = prepare_data(move_to_label(move))\n",
    "\n",
    "            input_batch.append(features)\n",
    "            label_batch.append(r)\n",
    "\n",
    "        board = make_move(board, move, player)\n",
    "        if player is 1:\n",
    "            player = -1\n",
    "        else:\n",
    "            player = 1\n",
    "        legal_moves = find_legal_moves(board, player)\n",
    "        if len(legal_moves) == 0:\n",
    "            if player is 1:\n",
    "                player = -1\n",
    "            else:\n",
    "                player = 1\n",
    "    #print(features)\n",
    "    input_batch.append(features)\n",
    "    label_batch.append(r)\n",
    "    if len(input_batch) > 128:\n",
    "        _, loss_ = sess.run([train_step, loss],\n",
    "                               feed_dict={img_data:input_batch,\n",
    "                                                ground_truths: label_batch,\n",
    "                                                keep_prob:probs,\n",
    "                                                learn_rate:eta})\n",
    "        input_batch = []\n",
    "        label_batch = []\n",
    "    #print(\"score out is\")\n",
    "    #print(loss_)\n",
    "\n",
    "    if (i % 50 is 0) and (i > 0) or (i+1) == (iterations+prev_stop) or (i % 1000 is 0):  \n",
    "        value_loss = value_error(validation_path, sess, diagn)\n",
    "        print('%s, Step %d, Loss = %.6f' % (datetime.now().strftime(\"%d. %b %H:%M:%S\"), i,\n",
    "                                                                          value_loss))\n",
    "        save_path = saver.save(sess, current_model + '.b')\n",
    "        if value_loss < 0.24:\n",
    "            break\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# always hanging around 0.693147\n",
    "# \"models/sl-v/tolf.ckpt\" náði 0.55975 í fyrstu þjálfun!\n",
    "# start =6e-5 virðist láta tolf-derivation lækka um 0.05 per 50 steps...\n",
    "# Þegar ég hækka learning rate þá virðist allt ýtast niðður í 0.5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15104\n"
     ]
    }
   ],
   "source": [
    "print(8*8*236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "board1 = initialize_game()\n",
    "zeros = np.count_nonzero(board1)\n",
    "print(zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(?, 2)\n",
    "(?, 1, 1, 2)\n",
    "(?, 2)\n",
    "117298\n",
    "start training\n",
    "\n",
    "First 1e-3 down to 0.4, then:\n",
    "\n",
    "start = 1e-4\n",
    "\n",
    "start training\n",
    "14. Oct 16:55:09, Step 0, Loss = 0.349850\n",
    "14. Oct 16:55:15, Step 100, Loss = 0.338470\n",
    "14. Oct 16:55:20, Step 200, Loss = 0.296196\n",
    "14. Oct 16:55:25, Step 300, Loss = 0.283280\n",
    "14. Oct 16:55:31, Step 400, Loss = 0.310574\n",
    "14. Oct 16:55:36, Step 500, Loss = 0.308730\n",
    "14. Oct 16:55:41, Step 600, Loss = 0.269805\n",
    "14. Oct 16:55:47, Step 700, Loss = 0.255041\n",
    "14. Oct 16:55:52, Step 800, Loss = 0.255202\n",
    "14. Oct 16:55:57, Step 900, Loss = 0.233139\n",
    "14. Oct 16:56:03, Step 1000, Loss = 0.230880\n",
    "14. Oct 16:56:08, Step 1100, Loss = 0.192403\n",
    "\n",
    "\"models/sl-v/nopool12.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"fewer\"params and no leaky relu\n",
    "\n",
    "4e-4\n",
    "\n",
    "117298\n",
    "start training\n",
    "14. Oct 18:42:53, Step 0, Loss = 0.669618\n",
    "14. Oct 18:42:59, Step 100, Loss = 0.640104\n",
    "14. Oct 18:43:05, Step 200, Loss = 0.627391\n",
    "14. Oct 18:43:11, Step 300, Loss = 0.682312\n",
    "14. Oct 18:43:19, Step 400, Loss = 0.622758\n",
    "14. Oct 18:43:24, Step 500, Loss = 0.418528\n",
    "14. Oct 18:43:29, Step 600, Loss = 0.381199\n",
    "14. Oct 18:43:36, Step 700, Loss = 0.289413\n",
    "14. Oct 18:43:43, Step 799, Loss = 0.283211\n",
    "done\n",
    "\n",
    "1e-4\n",
    "\n",
    "117298\n",
    "start training\n",
    "14. Oct 18:44:43, Step 100, Loss = 0.294863\n",
    "14. Oct 18:44:49, Step 200, Loss = 0.256158\n",
    "14. Oct 18:44:57, Step 300, Loss = 0.362265\n",
    "14. Oct 18:45:05, Step 400, Loss = 0.305164\n",
    "14. Oct 18:45:12, Step 500, Loss = 0.302925\n",
    "14. Oct 18:45:19, Step 600, Loss = 0.208198\n",
    "14. Oct 18:45:27, Step 700, Loss = 0.212496\n",
    "14. Oct 18:45:34, Step 800, Loss = 0.217972\n",
    "14. Oct 18:45:35, Step 807, Loss = 0.203382\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
