{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from othello_rules import *\n",
    "from othello_net import *\n",
    "from tensorflow.python.framework import ops\n",
    "from datetime import datetime\n",
    "from example_states import *\n",
    "from feature_extractor import *\n",
    "from training_utils import *\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def value_error(data_path, sess, diagnostics=False):\n",
    "    errors = []\n",
    "    validation_matches = get_all_matches(data_path)\n",
    "    #XXX: Delete this line when testing is faster\n",
    "    validation_matches = validation_matches[0:30]\n",
    "    for i in range(len(validation_matches)):\n",
    "        if diagnostics:\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>new game\")\n",
    "        match = validation_matches[i]\n",
    "        raw_match_movelist = match[8:]\n",
    "        unpacked_movelist = unpack('b'*60, raw_match_movelist)\n",
    "        black_score = match[6]\n",
    "        unpacked_black_score = unpack('b', black_score)\n",
    "        winner = -1 if unpacked_black_score[0] > 32 else 1\n",
    "        board = initialize_game()\n",
    "        player = -1\n",
    "        \n",
    "        if diagnostics:\n",
    "            print(unpacked_black_score)\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>winner is \" + str(winner))\n",
    "        movenr = 0\n",
    "        for move in unpacked_movelist:\n",
    "            if move == 0:\n",
    "                break\n",
    "            feature_path = 'cache/validation/features/features_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            label_path = 'cache/validation/labels/labels_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            if os.path.isfile(feature_path) and os.path.isfile(label_path):\n",
    "                features = np.load(feature_path)\n",
    "            else:\n",
    "                features = board_to_input(board, player)\n",
    "            input_batch = [features]\n",
    "            #s = 1 if player * (-1) == winner else 0\n",
    "            if winner == -1:\n",
    "                r = ([0, 1])\n",
    "                #r = [[0]]\n",
    "            else:\n",
    "                r = ([1, 0])\n",
    "                #r = [[1]]\n",
    "            label_batch = [r]\n",
    "            \n",
    "\n",
    "            if diagnostics and movenr > 42:\n",
    "                estimate = sess.run(score_out, feed_dict={img_data:input_batch, keep_prob:1.0})\n",
    "                predictions = sess.run(score_out, feed_dict={img_data:input_batch, keep_prob:1.0})\n",
    "                predic = predictions[0][0][0]\n",
    "                prediction = list_softmax(predic)\n",
    "                print(\"-new state-\")\n",
    "                print(\"actual value: \" + str(r))\n",
    "                #print(\"score_out: \" + str(estimate))\n",
    "                print(\"predictions: \" + str(prediction))\n",
    "            movenr += 1\n",
    "            error = sess.run(loss, feed_dict={img_data:input_batch, ground_truths: label_batch, keep_prob:1.0})\n",
    "            errors.append(error)\n",
    "            board = make_move(board, move, player)\n",
    "            if player is 1:\n",
    "                player = -1\n",
    "            else:\n",
    "                player = 1\n",
    "            legal_moves = find_legal_moves(board, player)\n",
    "            if len(legal_moves) == 0:\n",
    "                if player is 1:\n",
    "                    player = -1\n",
    "                else:\n",
    "                    player = 1\n",
    "                    \n",
    "        if np.count_nonzero(board) == 64:\n",
    "            error = sess.run(loss, feed_dict={img_data:input_batch, ground_truths: label_batch, keep_prob:1.0})\n",
    "            errors.append(error)\n",
    "            predic = sess.run(score_out, feed_dict={img_data:input_batch, ground_truths: label_batch, keep_prob:1.0})\n",
    "            predic = predic[0][0][0]\n",
    "            prediction = list_softmax(predic)\n",
    "            if diagnostics:\n",
    "                print(\"target is \")\n",
    "                print(r)\n",
    "                print(\"prediction is:\")\n",
    "                print(prediction)\n",
    "    return np.sum(errors) / len(errors)\n",
    "\n",
    "def list_softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    sf = np.exp(x)\n",
    "    sf = sf/np.sum(sf, axis=0)\n",
    "    return sf\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)\n",
    "\n",
    "def conv_nonparams2(tensor_input, conv_weights, conv_biases, keep_prob):\n",
    "    conv_in = conv(tensor_input, conv_weights)\n",
    "    conv_relu = lrelu(conv_in + conv_biases)\n",
    "    conv_drop = tf.nn.dropout(conv_relu, keep_prob)\n",
    "    return conv_drop\n",
    "\n",
    "def conv_weights2(i, o):\n",
    "    k = 2\n",
    "    shape = [k, k, i, o]\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv_nonparams3(tensor_input, conv_weights, conv_biases, keep_prob):\n",
    "    conv_in = conv(tensor_input, conv_weights, \"VALID\")\n",
    "    conv_relu = lrelu(conv_in + conv_biases)\n",
    "    conv_drop = tf.nn.dropout(conv_relu, keep_prob)\n",
    "    return conv_drop\n",
    "\n",
    "def create_value_net():\n",
    "    with tf.variable_scope(\"value_network\"):\n",
    "        img_data = tf.placeholder(tf.float32, shape=[None, 8, 8, 28], name=\"img_data\")\n",
    "        keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "        #convolutional layers \n",
    "        i = 28; o = 32;\n",
    "        conv1_weights = conv_weights(i, o)\n",
    "        conv1_biases = conv_biases(o)\n",
    "        conv1_out = conv_nonparams2(img_data, conv1_weights, conv1_biases, keep_prob)\n",
    "        #pool1 = max_pool_2x2(conv1_out)\n",
    "        i = o; o = 32;\n",
    "        conv2_weights = conv_weights(i, o)\n",
    "        conv2_biases = conv_biases(o)\n",
    "        conv2_out = conv_nonparams2(conv1_out, conv2_weights, conv2_biases, keep_prob)\n",
    "        #pool2 = max_pool_2x2(conv2_out)\n",
    "        i = o; o = 32;\n",
    "        conv3_weights = conv_weights2(i, o)\n",
    "        conv3_biases = conv_biases(o)\n",
    "        conv3_out = conv_nonparams2(conv2_out, conv3_weights, conv3_biases, keep_prob)\n",
    "        \n",
    "        i = o; o = 32;\n",
    "        conv4_weights = conv_weights2(i, o)\n",
    "        conv4_biases = conv_biases(o)\n",
    "        conv4_out = conv_nonparams2(conv3_out, conv4_weights, conv4_biases, keep_prob)\n",
    "        \n",
    "\n",
    "        \n",
    "        k = 1; i = o; o = 2;\n",
    "        s_weights = weight_variable([k, k, i, o])\n",
    "        s_biases = bias_variable([o])\n",
    "        s_out = conv_nonparams(conv4_out, s_weights, s_biases, keep_prob)\n",
    "        \n",
    "        k = 8; i = o; o = 2;\n",
    "        score_weights = weight_variable([k, k, i, o])\n",
    "        score_biases = bias_variable([o])\n",
    "        score_out = conv_nonparams3(s_out, score_weights, score_biases, keep_prob)\n",
    "        score_out_flat = tf.reshape(score_out, [-1, o])\n",
    "        #final layer\n",
    "        #Don't actually use this layer here\n",
    "        predictions = softmax(score_out, o)\n",
    "\n",
    "        #training block:\n",
    "        label = tf.placeholder(tf.float32, shape=[None, 2], name=\"ground_truths\")\n",
    "        learn_rate = tf.placeholder(tf.float32, name=\"eta\")\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(score_out_flat, label))\n",
    "        policy_network_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        reg_loss = tf.reduce_sum([tf.reduce_sum(tf.square(x)) for x in policy_network_variables])\n",
    "        optimizer = tf.train.AdamOptimizer(learn_rate)\n",
    "        train_step = optimizer.minimize(loss)\n",
    "        sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "        return sess.graph, img_data, train_step, optimizer, label, loss, predictions, keep_prob, learn_rate, score_out\n",
    "\n",
    "    # MAKE SURE that the topology of this network is the same as the policy network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117298\n",
      "start training\n",
      "15. Oct 13:26:54, Step 21000, Loss = 0.544263\n",
      "15. Oct 13:27:02, Step 21010, Loss = 0.544098\n",
      "15. Oct 13:27:09, Step 21020, Loss = 0.543902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 497, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 466, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python2.7/inspect.py\", line 448, in getsourcefile\n",
      "    if 'b' in mode and string.lower(filename[-len(suffix):]) == suffix:\n",
      "  File \"/usr/lib/python2.7/string.py\", line 222, in lower\n",
      "    def lower(s):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1822\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1824\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1406\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1314\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m             )\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1196\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "graph, img_data, train_step, optimizer, ground_truths, loss, pred_up, keep_prob, learn_rate, score_out = create_value_net()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess.run(init_op)\n",
    "#nopool7 gat fundið hver sigrar leiki, 0.2~ loss\n",
    "\n",
    "# Prófa noends9 upp á sanity checks\n",
    "\n",
    "# \"models/sl-v/noends9.ckpt.b\" hefur 0.238 end state loss og notar ekki bara end-states\n",
    "\n",
    "# >>>>> \"models/sl-v/players_g.ckpt\" hefur 0.544 all state loss og notar alltalltallt\n",
    "# Þjálfaði aðallega í 1e-5 eða svo \n",
    "\n",
    "current_model = \"models/sl-v/players_g.ckpt.b\"\n",
    "if os.path.isfile(current_model):\n",
    "    saver.restore(sess, current_model)\n",
    "validation_path = \"validation/\"\n",
    "matches = get_all_matches('training/')\n",
    "print(len(matches))\n",
    "\n",
    "# Byrjum þjálfunina\n",
    "print(\"start training\")\n",
    "#print(\"starting error:\" + str(avg_error(validation_path, sess)))\n",
    "#print('%s: Step %d: Prediction accuracy = %.2f' % (datetime.now(), 0,\n",
    "#                                                      prediction_accuracy()/float(60)))\n",
    "diagn = False\n",
    "if diagn:\n",
    "    iterations = 1\n",
    "else:\n",
    "    #iterations = len(matches)\n",
    "    iterations = 100\n",
    "prev_stop = 21000\n",
    "#upper_limit = np.max(prev_stop+iterations, len(matches))\n",
    "probs = 1\n",
    "eta = 1e-6\n",
    "input_batch = []\n",
    "label_batch = []\n",
    "for i in range(prev_stop, prev_stop+iterations):\n",
    "    if i > 35000 and i < 40000:\n",
    "        continue\n",
    "    #TODO: Skrifa þetta fall\n",
    "    #input_batch, label_batch = prepare_train_batch(train_ids, batch_size, do_flips, do_rots, data_path)\n",
    "    current_match = matches[i]\n",
    "    raw_match_movelist = current_match[8:]\n",
    "    unpacked_movelist = unpack('b'*60, raw_match_movelist)\n",
    "    black_score = current_match[6]\n",
    "    unpacked_black_score = unpack('b', black_score)\n",
    "    \n",
    "    #XXX: Temporary check for the value network, do this properly later\n",
    "    if unpacked_black_score[0] > 32:\n",
    "        winner = -1\n",
    "    else:\n",
    "        winner = 1\n",
    "    \n",
    "    board = initialize_game()\n",
    "    training_stability = np.zeros((8,8))\n",
    "    player = -1\n",
    "    \n",
    "    # One training batch is all the data from one match\n",
    "    if winner == -1:\n",
    "        r = ([0, 1])\n",
    "    else:\n",
    "        r = ([1, 0])\n",
    "    \n",
    "    for move in unpacked_movelist:\n",
    "        if move == 0:\n",
    "            break\n",
    "\n",
    "        if np.random.rand()>0.0:\n",
    "            feature_path = 'cache/training/features/features_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            label_path = 'cache/training/labels/labels_' + str(i) + \"_\" + str(move) + \".npy\"\n",
    "            if os.path.isfile(feature_path) and os.path.isfile(label_path):\n",
    "                try:\n",
    "                    features = np.load(feature_path)\n",
    "                    label = np.load(label_path)\n",
    "                except:\n",
    "                    print(\"data corruption in match \" + str(i))\n",
    "                    features = board_to_input(board, player)\n",
    "                    label = prepare_data(move_to_label(move))\n",
    "            else:\n",
    "                features = board_to_input(board, player)\n",
    "                label = prepare_data(move_to_label(move))\n",
    "            features = np.array(features)\n",
    "            input_batch.append(features)\n",
    "            label_batch.append(r)\n",
    "            \n",
    "            features_upright = flip_features(features, 'upright')\n",
    "            input_batch.append(features_upright)\n",
    "            label_batch.append(r)\n",
    "\n",
    "            # Then the other diagonal\n",
    "            features_upleft = flip_features(features, 'upleft')\n",
    "            input_batch.append(features_upleft)\n",
    "            label_batch.append(r)\n",
    "\n",
    "            # Then both diagonals\n",
    "            features_both = flip_features(features, 'both')\n",
    "            input_batch.append(features_both)\n",
    "            label_batch.append(r)\n",
    "\n",
    "        board = make_move(board, move, player)\n",
    "        if player is 1:\n",
    "            player = -1\n",
    "        else:\n",
    "            player = 1\n",
    "        legal_moves = find_legal_moves(board, player)\n",
    "        if len(legal_moves) == 0:\n",
    "            if player is 1:\n",
    "                player = -1\n",
    "            else:\n",
    "                player = 1\n",
    "    #print(features)\n",
    "    #input_batch.append(features)\n",
    "    #label_batch.append(r)\n",
    "    if len(input_batch) > 128:\n",
    "        _, loss_ = sess.run([train_step, loss],\n",
    "                               feed_dict={img_data:input_batch,\n",
    "                                                ground_truths: label_batch,\n",
    "                                                keep_prob:probs,\n",
    "                                                learn_rate:eta})\n",
    "        input_batch = []\n",
    "        label_batch = []\n",
    "    #print(\"score out is\")\n",
    "    #print(loss_)\n",
    "\n",
    "    if (i % 10 is 0) and (i > 0) or (i+1) == (iterations+prev_stop) or (i % 1000 is 0):  \n",
    "        value_loss = value_error(validation_path, sess, diagn)\n",
    "        print('%s, Step %d, Loss = %.6f' % (datetime.now().strftime(\"%d. %b %H:%M:%S\"), i,\n",
    "                                                                          value_loss))\n",
    "        save_path = saver.save(sess, current_model + '.b')\n",
    "        if value_loss < 0.24:\n",
    "            break\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of doom: 0.693147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "board1 = initialize_game()\n",
    "zeros = np.count_nonzero(board1)\n",
    "print(zeros)\n",
    "f = board_to_input(board1, -1)\n",
    "black = np.ones((8,8,1))\n",
    "print(featurez.shape)\n",
    "addone = np.dstack((f, black))\n",
    "print(addone.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "(?, 2)\n",
    "(?, 1, 1, 2)\n",
    "(?, 2)\n",
    "117298\n",
    "start training\n",
    "\n",
    "First 1e-3 down to 0.4, then:\n",
    "\n",
    "start = 1e-4\n",
    "\n",
    "start training\n",
    "14. Oct 16:55:09, Step 0, Loss = 0.349850\n",
    "14. Oct 16:55:15, Step 100, Loss = 0.338470\n",
    "14. Oct 16:55:20, Step 200, Loss = 0.296196\n",
    "14. Oct 16:55:25, Step 300, Loss = 0.283280\n",
    "14. Oct 16:55:31, Step 400, Loss = 0.310574\n",
    "14. Oct 16:55:36, Step 500, Loss = 0.308730\n",
    "14. Oct 16:55:41, Step 600, Loss = 0.269805\n",
    "14. Oct 16:55:47, Step 700, Loss = 0.255041\n",
    "14. Oct 16:55:52, Step 800, Loss = 0.255202\n",
    "14. Oct 16:55:57, Step 900, Loss = 0.233139\n",
    "14. Oct 16:56:03, Step 1000, Loss = 0.230880\n",
    "14. Oct 16:56:08, Step 1100, Loss = 0.192403\n",
    "\n",
    "\"models/sl-v/nopool12.ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"fewer\"params and no leaky relu\n",
    "\n",
    "4e-4\n",
    "\n",
    "117298\n",
    "start training\n",
    "14. Oct 18:42:53, Step 0, Loss = 0.669618\n",
    "14. Oct 18:42:59, Step 100, Loss = 0.640104\n",
    "14. Oct 18:43:05, Step 200, Loss = 0.627391\n",
    "14. Oct 18:43:11, Step 300, Loss = 0.682312\n",
    "14. Oct 18:43:19, Step 400, Loss = 0.622758\n",
    "14. Oct 18:43:24, Step 500, Loss = 0.418528\n",
    "14. Oct 18:43:29, Step 600, Loss = 0.381199\n",
    "14. Oct 18:43:36, Step 700, Loss = 0.289413\n",
    "14. Oct 18:43:43, Step 799, Loss = 0.283211\n",
    "done\n",
    "\n",
    "1e-4\n",
    "\n",
    "117298\n",
    "start training\n",
    "14. Oct 18:44:43, Step 100, Loss = 0.294863\n",
    "14. Oct 18:44:49, Step 200, Loss = 0.256158\n",
    "14. Oct 18:44:57, Step 300, Loss = 0.362265\n",
    "14. Oct 18:45:05, Step 400, Loss = 0.305164\n",
    "14. Oct 18:45:12, Step 500, Loss = 0.302925\n",
    "14. Oct 18:45:19, Step 600, Loss = 0.208198\n",
    "14. Oct 18:45:27, Step 700, Loss = 0.212496\n",
    "14. Oct 18:45:34, Step 800, Loss = 0.217972\n",
    "14. Oct 18:45:35, Step 807, Loss = 0.203382\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
