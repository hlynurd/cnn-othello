                     eta = 2e-4,
                     discount_factor=1
        if n > 500:
            if temp_reset:
                avg_vector_1 = []
		...
            rl_reinforce.updateModel()
            ...


e/f
eftirfarandi error gaf kjaftæði:
10. Oct 17:12:20, Step 0, loss_1 = 3.092, loss_2 = 4.550 

frekar:
10. Oct 17:15:08, Step 100, loss_1 = 2.409, loss_2 = 2.764

starting self play
10. 17:17:21, Step 100: first = 50, second = 47
10. 17:17:22, Step 100: first winrate = 0.50, second winrate = 0.47
10. 17:19:24, Step 200: first = 47, second = 44	
10. 17:19:25, Step 200: first winrate = 0.48, second winrate = 0.46
10. 17:21:19, Step 300: first = 60, second = 38
10. 17:21:20, Step 300: first winrate = 0.52, second winrate = 0.43
10. 17:22:58, Step 400: first = 50, second = 48
10. 17:22:59, Step 400: first winrate = 0.52, second winrate = 0.44

10. 17:24:41, Step 500: first = 50, second = 44
10. 17:24:42, Step 500: first winrate = 0.51, second winrate = 0.44 <<<<<<

10. 17:26:22, Step 600: first = 56, second = 42
10. 17:26:22, Step 600: first winrate = 0.56, second winrate = 0.42

10. 17:28:04, Step 700: first = 61, second = 36
10. 17:28:05, Step 700: first winrate = 0.58, second winrate = 0.39
10. 17:29:39, Step 800: first = 56, second = 42
10. 17:29:40, Step 800: first winrate = 0.58, second winrate = 0.40
10. 17:31:25, Step 900: first = 60, second = 37
10. 17:31:26, Step 900: first winrate = 0.58, second winrate = 0.39
10. 17:33:05, Step 1000: first = 55, second = 41
10. 17:33:06, Step 1000: first winrate = 0.58, second winrate = 0.40
10. 17:34:43, Step 1100: first = 41, second = 55
10. 17:34:44, Step 1100: first winrate = 0.55, second winrate = 0.42
10. 17:36:18, Step 1200: first = 56, second = 41
10. 17:36:19, Step 1200: first winrate = 0.55, second winrate = 0.42
10. 17:38:03, Step 1300: first = 51, second = 47
10. 17:38:04, Step 1300: first winrate = 0.55, second winrate = 0.43 <<<<<<

            if winner is -1:
                reward = 1 if j% 2 is 0 else -0.1
            else:
                reward = -0.1 if j% 2 is 0 else 1


starting self play
10. 17:46:13, Step 100: first = 49, second = 49
10. 17:47:35, Step 200: first = 46, second = 48
10. 17:48:55, Step 300: first = 51, second = 43
10. 17:50:15, Step 400: first = 47, second = 48
10. 17:51:38, Step 500: first = 39, second = 55
10. 17:51:41, Results before learning : first wr = 0.45, second wr = 0.50
10. 17:53:09, Step 600: first = 49, second = 47
10. 17:54:40, Step 700: first = 62, second = 36
action probabilities
[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan
  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan
  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan
  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan  nan
  nan  nan  nan  nan]
[[  0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00
    1.44e-25   3.31e-10]
 [  0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00
    1.55e-32   4.35e-13]
 [  0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00   0.00e+00
    6.28e-26   1.81e-10]
 [  0.00e+00   0.00e+00   0.00e+00   0.00e+00   2.74e-31   1.70e-18
    1.90e-14   1.10e-08]
 [  3.82e-34   0.00e+00   0.00e+00   8.19e-27   5.94e-17   1.38e-12
    8.25e-13   9.85e-09]
 [  1.46e-14   1.60e-24   1.77e-22   2.76e-18   7.11e-15   1.48e-14
    1.12e-15   3.92e-11]
 [  1.17e-11   1.37e-19   2.20e-16   2.94e-16   1.71e-16   7.53e-15
    1.33e-18   6.10e-14]
 [  4.86e-08   5.48e-13   2.48e-11   3.75e-10   2.11e-10   5.89e-11
    8.02e-13   3.60e-09]]
[[ 0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.  0.  0.]]
illegal action sampled:
11
in state
[[-1.  0.  0.  0.  0.  1.  1.  1.]
 [ 0.  1.  1.  1.  1.  1.  1.  1.]
 [ 0.  0.  1.  1. -1.  1.  1.  1.]
 [ 1.  1.  1.  1.  1.  1.  1.  1.]
 [ 1.  1. -1.  1.  1.  1.  1.  1.]
 [ 1.  1.  1. -1. -1.  1.  1.  1.]
 [ 1.  1.  1.  1.  1.  1.  1.  1.]
 [ 1.  1.  1.  1.  1.  1.  1.  1.]]
10. 17:56:12, Step 800: first = 52, second = 42
10. 17:57:49, Step 900: first = 51, second = 45
10. 17:59:28, Step 1000: first = 50, second = 48
10. 17:59:30, Results after learning : first wr = 0.55, second wr = 0.45

k/l

change:

            if winner is -1:
                reward = 1 if j% 2 is 0 else -0.1
            else:
                reward = -0.1 if j% 2 is 0 else 1


                     eta = 2e-4,
                     discount_factor=1

10. Oct 17:41:23, Step 0, loss_1 = 32.283, loss_2 = 35.331
10. Oct 17:41:53, Step 100, loss_1 = 2.799, loss_2 = 4.075
10. Oct 17:42:24, Step 200, loss_1 = 2.592, loss_2 = 3.000
10. Oct 17:42:58, Step 299, loss_1 = 2.457, loss_2 = 2.740
	
starting self play
10. 21:54:46, Step 100: first = 53, second = 42
10. 21:56:07, Step 200: first = 40, second = 59
10. 21:57:31, Step 300: first = 57, second = 41
10. 21:59:05, Step 400: first = 44, second = 53
10. 22:00:41, Step 500: first = 60, second = 36
10. 22:09:17, Results before learning : first wr = 0.51, second wr = 0.46
10. 22:02:19, Step 600: first = 66, second = 34
10. 22:04:08, Step 700: first = 61, second = 35
10. 22:05:49, Step 800: first = 65, second = 30
10. 22:07:31, Step 900: first = 52, second = 46
10. 22:09:15, Step 1000: first = 52, second = 46
10. 22:09:17, Results after learning : first wr = 0.59, second wr = 0.38


o/p:

10. Oct 17:41:23, Step 0, loss_1 = 32.283, loss_2 = 35.331
10. Oct 17:41:53, Step 100, loss_1 = 2.799, loss_2 = 4.075
10. Oct 17:42:24, Step 200, loss_1 = 2.592, loss_2 = 3.000
10. Oct 17:42:58, Step 299, loss_1 = 2.457, loss_2 = 2.740

